title = "a basic config for pre-training on aol benchmark."

# [Model]
model_type = "ANCE"
pretrained_query_encoder = "../COTED/checkpoints/ad-hoc-ance-msmarco"
pretrained_passage_encoder = "../COTED/checkpoints/ad-hoc-ance-msmarco"

# model_type = "DPR-NQ"
# pretrained_query_encoder = "facebook/dpr-question_encoder-single-nq-base"
# pretrained_passage_encoder = "facebook/dpr-ctx_encoder-single-nq-base"

num_negatives = 1   # actually 1 + batchsize - 1
max_concat_length = 128
max_query_length = 64
max_doc_length = 128

# [Train]
num_train_epochs = 4   # !!
per_gpu_train_batch_size = 32    # !!
n_gpu = 1   # !!
disable_tqdm = false    # !!

save_steps = 0.2   # !! int (steps) or float (ratio of a epoch)
print_steps =  0.001  # print the loss
learning_rate = 1e-5
weight_decay = 0.0
adam_epsilon = 1e-8
num_warmup_steps = 0
max_grad_norm = 1.0

enable_last_repsone = true
seed = 42

use_data_percent = 1.0    # !!


# [Input Data]
train_file_path = "../Dataset/aol/preprocessed/train.json"

# [Output]
overwrite_output_dir = true
log_dir_path = "./Output/pretrain_aol/Log"
model_output_path = "./Output/pretrain_aol/Checkpoint"



